{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4P1_S15_Comb_FG_Depth_Prediction_V0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "apBxYAZbXG0F",
        "colab_type": "code",
        "outputId": "cda7d944-b8a5-4f3b-ca49-97fe856d9c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 19 13:26:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsX-oaLbXPrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e6d5e4a0-5282-42a6-aed1-8f7a46e4df6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymD5LhUiXSlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0e84dd1-0437-470b-b7c7-575319524a08"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pkgutil\n",
        "import importlib\n",
        "import os\n",
        "%matplotlib inline\n",
        "%config IPCompleter.greedy=True\n",
        "%reload_ext autoreload\n",
        "import seaborn as sns\n",
        "import io\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from itertools import groupby\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "from time import time\n",
        "from datetime import datetime \n",
        "import gc\n",
        "sns.set()\n",
        "from zipfile import ZipFile\n",
        "import zipfile\n",
        "\n",
        "# install \"apex\" model for mixed precision training if required.. this is needed for LRFinder\n",
        "if pkgutil.find_loader(\"apex\") is None:\n",
        "   print(\"****apex module does not exist..hence installing*****\")\n",
        "   !pip install -U git+https://www.github.com/NVIDIA/apex --no-cache-dir\n",
        "\n",
        "import albumentations\n",
        "print(albumentations.__version__) # check version\n",
        "\n",
        "# This is to install and use albumentations latest package v0.4.5\n",
        "album_version_needed = \"0.4.5\"\n",
        "if albumentations.__version__ != album_version_needed:\n",
        "  !pip install albumentations==0.4.5   # 0.4.5 is the latest albumentation version\n",
        "print('Pytorch version:', torch.__version__)\n",
        "\n",
        "!pip install kornia\n",
        "from kornia.losses import SSIM"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "****apex module does not exist..hence installing*****\n",
            "Collecting git+https://www.github.com/NVIDIA/apex\n",
            "  Cloning https://www.github.com/NVIDIA/apex to /tmp/pip-req-build-sczw6apz\n",
            "  Running command git clone -q https://www.github.com/NVIDIA/apex /tmp/pip-req-build-sczw6apz\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp36-none-any.whl size=177174 sha256=60867b2e7114f8ef70a3d69a2d146079a207a63cb772d3f209c05f9b11d1d30f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4rbjm5p4/wheels/08/3e/36/a75a9914e497fe42598f9dbe67496b2b300a8851f4d396a285\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n",
            "0.1.12\n",
            "Collecting albumentations==0.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/40/a343ecacc7e22fe52ab9a16b84dc6165ba05ee17e3729adeb3e2ffa2b37b/albumentations-0.4.5.tar.gz (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.12.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.2.0)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64378 sha256=90bbc29906adf5c3dc5486f057f1ca626fbe79f14cc2b56a24299a0d99d93d12\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/a0/61/e50f93165a5ec7e7f5d65064e513239505bc4c06d2289557d3\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=16bfb7f04fe3e4871835e9ae084110de9f9f446d009c4fac8875354e587ecd86\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "albumentations",
                  "imgaug"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pytorch version: 1.5.0+cu101\n",
            "Collecting kornia\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/60/f0c174c4a2a40b10b04b37c43f5afee3701cc145b48441a2dc5cf9286c3c/kornia-0.3.1-py2.py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->kornia) (0.16.0)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcUEtIwzXcfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "fcb5be3b-3e4a-4361-97aa-aa681583ecb2"
      },
      "source": [
        "os.mkdir('/content/sample_data/FG_BG')\n",
        "os.mkdir('/content/sample_data/Mask')\n",
        "os.mkdir('/content/sample_data/Depth')\n",
        "\n",
        "FG_BG_zip =  ZipFile(\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_400K.zip\", 'r')\n",
        "Mask_zip  = ZipFile(\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_Mask_400K.zip\", 'r')\n",
        "Depth_zip = ZipFile(\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_Depth_400K.zip\", 'r')\n",
        "all_files_FG_BG = [info.filename for info in FG_BG_zip.infolist() if not info.is_dir()]\n",
        "all_files_Mask  = [info.filename for info in Mask_zip.infolist() if not info.is_dir()]\n",
        "all_files_Depth = [info.filename for info in Depth_zip.infolist() if not info.is_dir()]\n",
        "print(len(all_files_FG_BG))\n",
        "print(len(all_files_Mask))\n",
        "print(len(all_files_Depth))\n",
        "\n",
        "path_fg_bg  = '/content/sample_data/FG_BG/'\n",
        "path_mask   = '/content/sample_data/Mask/' \n",
        "path_depth  = '/content/sample_data/Depth/'\n",
        "\n",
        "t1 = time()\n",
        "k = 0\n",
        "for img_file in all_files_FG_BG[0:40000]:\n",
        "    if img_file.endswith('jpg'):\n",
        "        imgdata = FG_BG_zip.read(img_file)\n",
        "        img = Image.open(io.BytesIO(imgdata))\n",
        "        file_name = img_file.split('/')[-1].split('.')[0] + '.jpg'\n",
        "        img.save(f'{path_fg_bg}{file_name}')\n",
        "        k += 1\n",
        "print('FG_BG Written:',k) \n",
        "\n",
        "k = 0\n",
        "for img_file in all_files_Mask[0:]:\n",
        "    if img_file.endswith('jpg'):\n",
        "        imgdata = Mask_zip.read(img_file)\n",
        "        img = Image.open(io.BytesIO(imgdata))\n",
        "        file_name = img_file.split('/')[-1].split('.')[0] + '.jpg'\n",
        "        img.save(f'{path_mask}{file_name}')\n",
        "        k += 1\n",
        "print('Masks Written:',k) \n",
        "\n",
        "k = 0\n",
        "for img_file in all_files_Depth[0:]:\n",
        "    if img_file.endswith('jpg'):\n",
        "        imgdata = Depth_zip.read(img_file)\n",
        "        img = Image.open(io.BytesIO(imgdata))\n",
        "        file_name = img_file.split('/')[-1].split('.')[0] + '.jpg'\n",
        "        img.save(f'{path_depth}{file_name}')\n",
        "        k += 1\n",
        "print('Depth Written:',k) \n",
        "\n",
        "!cp -r '/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/BG_and_Its_Flip' '/content/sample_data/'\n",
        "!cp '/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_Filename_withflip_Logs.txt' '/content/sample_data/'\n",
        "\n",
        "t2 = time()\n",
        "print(f'Copy took {(t2-t1)/60:.5f} minutes')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6fea7244e631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/Depth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mFG_BG_zip\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_400K.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mMask_zip\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_Mask_400K.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mDepth_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_Depth_400K.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/EVA4P1_S15/FG_BG_Mask_Depth/FG_BG_400K.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFopA0YBXg1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_fg_bg = open('/content/sample_data/FG_BG_Filename_withflip_Logs.txt',\"r\")\n",
        "content_list = log_fg_bg.readlines()\n",
        "print('No: of records in log_fg_bg:',len(content_list))\n",
        "print(content_list[0])\n",
        "log_fg_bg.close()\n",
        "\n",
        "data_root = Path('/content/sample_data')\n",
        "f1, f2, f3, f4 = data_root/'FG_BG', data_root/'BG_and_Its_Flip', data_root/'Mask', data_root/'Depth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPglYPf5XqNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(list(f1.iterdir())))\n",
        "print(len(list(f2.iterdir())))\n",
        "print(len(list(f3.iterdir())))\n",
        "print(len(list(f4.iterdir())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR5nA64cXxNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs   = 25\n",
        "rows = 5\n",
        "size = 256\n",
        "prnt = 100\n",
        "drpout = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW544V3yX9AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gt_transform = transforms.Compose([transforms.Resize((256,256)),\n",
        "                                      transforms.ToTensor(),])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G9HlMniYL98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg_transform = transforms.Compose([#transforms.Resize((256,256)),\n",
        "                                       transforms.ColorJitter(brightness =0.05,contrast=0.05,saturation=0.05,hue=0.05),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RszUyYg_Yb2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fg_bg_transform = transforms.Compose([#transforms.Resize((256,256)),\n",
        "                                       transforms.ColorJitter(brightness =0.05,contrast=0.05,saturation=0.05,hue=0.05),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhF8vNh6YoHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MasterDataset(Dataset):\n",
        "  def __init__(self,data_root,content_list, do_transform=True):\n",
        "    self.f1_files     = list(f1.glob('*.jpg'))\n",
        "    self.content_list = content_list\n",
        "    self.do_transform    = do_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.f1_files)  \n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    fg_bg_name   = self.f1_files[index].stem\n",
        "    fg_bg_idx    = fg_bg_name.split('_')[-1]\n",
        "    bg_name = '/content/sample_data/BG_and_Its_Flip/' + self.content_list[int(fg_bg_idx)-1].split(',')[1]\n",
        "    mask_name    = '/content/sample_data/Mask/' + 'Img_fg_bg_mask' + str(fg_bg_idx) + '.jpg'\n",
        "    depth_name   = '/content/sample_data/Mask/' + 'Img_fg_bg_' + str(fg_bg_idx) + '_depth.jpg'\n",
        "    f1_image = Image.open(self.f1_files[index])  \n",
        "    f2_image = Image.open(f'{bg_name}')\n",
        "    f3_image = Image.open(f'{mask_name}')\n",
        "    f4_image = Image.open(f'{depth_name}')\n",
        "\n",
        "    if self.do_transform:\n",
        "      f1_image = bg_transform(f1_image)\n",
        "      f2_image = fg_bg_transform(f2_image)\n",
        "      f3_image = (gt_transform(f3_image) > 0.8).float()\n",
        "      f4_image = gt_transform(f4_image)\n",
        "\n",
        "    return {'f1':f1_image, 'f2':f2_image, 'f3':f3_image, 'f4':f4_image}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjLTlX9ac9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = MasterDataset(data_root, content_list, train_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CmqGkkxbbVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(k, v.shape) for k, v in train_ds[0].items() if k != 'index']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdssp-SZbmtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, batch_size = bs, shuffle = True, pin_memory = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grbsEvhubrWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_dl))\n",
        "type(sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSIEU7q0bvK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(k, v.shape) for k, v in sample.items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uvSA-w5b335",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = sample['f3']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzzRfXNab6wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(tensors, figsize= (10,10), *args, **kwargs):\n",
        "  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)  \n",
        "  grid_image  = grid_tensor.permute(1, 2, 0)\n",
        "  plt.figure(figsize = figsize)\n",
        "  plt.imshow(grid_image)\n",
        "  plt.xticks([])  \n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81an8vFrcHBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_pred(tensors, *args, **kwargs):\n",
        "  tensors = (tensors * std[None, : , None, None]) + mean[None, :, None, None]\n",
        "  show(tensors, *args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ-r9ZjHcMnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_and_save(tensors, name, figsize=(20,20), *args, **kwargs):\n",
        "  try:\n",
        "    tensors = tensors.detach().cpu()\n",
        "  except:\n",
        "    pass\n",
        "  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)\n",
        "  grid_image  = grid_tensor.permute(1, 2, 0)\n",
        "  plt.figure(figsize = figsize)\n",
        "  plt.imshow(grid_image)\n",
        "  plt.xticks([])  \n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.savefig(name, bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhJiayXIczhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show(imgs, nrow=rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbBBY4gec8ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DownResNet(nn.Module):\n",
        "  def __init__(self,inchannels,outchannels):\n",
        "    super(DownResNet, self).__init__()\n",
        "\n",
        "    self.conv1  = nn.Conv2d(inchannels, outchannels, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    self.conv12 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(outchannels)\n",
        "    self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    self.conv2  = nn.Conv2d(outchannels, outchannels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.conv22 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(outchannels)\n",
        "\n",
        "    self.conv1x1down = nn.Conv2d(inchannels, outchannels,kernel_size=1, stride=2, padding=0, bias=False)\n",
        "\n",
        "  def forward(self,x):\n",
        "    identity = self.conv1x1down(x)\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv12(out)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv22(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlH-jdV9j4Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UpResNet(nn.Module):\n",
        "  def __init__(self, inchannels, outchannels):\n",
        "    super(UpResNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(outchannels, outchannels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.conv12 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(outchannels)\n",
        "    self.relu = nn.ReLU(inplace = False)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(outchannels, outchannels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.conv22 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(outchannels)\n",
        "\n",
        "    self.conv1x1down = nn.ConvTranspose2d(inchannels, outchannels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = self.conv1x1down(x)\n",
        "    out = self.conv1(identity)\n",
        "    out = self.conv12(out)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv22(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "  # out += x\n",
        "\n",
        "    out = self.relu(out)  \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwi46bmCnAaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BGDPTH(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BGDPTH, self).__init__()\n",
        "\n",
        "    self.convFirst = nn.Sequential(nn.Conv2d(6,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(inplace=False))\n",
        "    \n",
        "    self.maxpool = nn.MaxPool2d(3, stride = 2, padding =1)\n",
        "\n",
        "    self.rb1 = DownResNet(64,128)\n",
        "    self.rb2 = DownResNet(128,256)\n",
        "    self.rb3 = DownResNet(256,512)\n",
        "\n",
        "    self.rb4 = UpResNet(512, 256)\n",
        "    self.rb5 = UpResNet(256, 128)\n",
        "    self.rb6 = UpResNet(128, 64)\n",
        "\n",
        "    self.rb7 = UpResNet(64,64)\n",
        "\n",
        "    self.rb8 = UpResNet(64,32)\n",
        "\n",
        "    self.convLast = nn.Sequential(nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0, bias=False),)\n",
        "\n",
        "    self.rb4D = UpResNet(512, 256)\n",
        "    self.rb5D = UpResNet(256, 128) \n",
        "    self.rb6D = UpResNet(128, 64)\n",
        "\n",
        "    self.rb7D = UpResNet(64, 64)\n",
        "\n",
        "    self.rb8D = UpResNet(64, 32)\n",
        "\n",
        "    self.convLastD = nn.Sequential(nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0, bias=False),)\n",
        "\n",
        "  def forward(self, sample):\n",
        "    f11 = sample['f1']\n",
        "    f22 = sample['f2']\n",
        "    f   = torch.cat([f11,f22], dim=1)\n",
        "\n",
        "    out0 = self.convFirst(f)\n",
        "    out1 = self.maxpool(out0)\n",
        "    out2 = self.rb1(out1)\n",
        "    out3 = self.rb2(out2)\n",
        "    out4 = self.rb3(out3)\n",
        "\n",
        "    out4 = nn.functional.interpolate(out4, scale_factor=2, mode='bilinear')\n",
        "\n",
        "    out5 = self.rb4(out4)\n",
        "    out5 += out3\n",
        "    out5 = nn.functional.interpolate(out5, scale_factor=2, mode='bilinear')\n",
        "    out6 = self.rb5(out5)\n",
        "    out6 += out2 \n",
        "    out6 = nn.functional.interpolate(out6, scale_factor=2, mode='bilinear')\n",
        "    out7 = self.rb6(out6)\n",
        "    out7 += out1\n",
        "    out7 = nn.functional.interpolate(out7, scale_factor=2, mode='bilinear')\n",
        "    out8 = self.rb7(out7)\n",
        "    out8 += out0\n",
        "\n",
        "    out9 = nn.functional.interpolate(out8, scale_factor=2, mode='bilinear')\n",
        "    out9 = self.rb8(out9)\n",
        "\n",
        "    outB = self.convLast(out9)\n",
        "\n",
        "    out5D = self.rb4D(out4)\n",
        "    out5D += out3\n",
        "    out5D = nn.functional.interpolate(out5D, scale_factor=2, mode='bilinear')\n",
        "    out6D = self.rb5D(out5D)\n",
        "    out6D += out2\n",
        "    out6D = nn.functional.interpolate(out6D, scale_factor=2, mode='bilinear')\n",
        "    out7D = self.rb6D(out6D)\n",
        "    out7D += out1\n",
        "    out7D = nn.functional.interpolate(out7D, scale_factor=2, mode='bilinear')\n",
        "    out8D = self.rb7D(out7D)\n",
        "    out8D += out0\n",
        "\n",
        "    out9D = nn.functional.interpolate(out8D, scale_factor=2, mode='bilinear')\n",
        "    out9D = self.rb8D(out9D)\n",
        "\n",
        "    outD  = self.convLastD(out9D)\n",
        "\n",
        "    return outB, outD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uifoKkfgwmJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(ms):\n",
        "  for m in ms.modules():\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "      m.weight.data = m.init.kaiming_normal_(m.weight.data, mode='fan_out',nonlinearity='relu')\n",
        "    elif classname.find('ConvTranspose2d') != -1:\n",
        "      m.weight.data = m.init.kaiming_normal_(m.weight.data, mode='fan_out',nonlinearity='relu')\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.constant_(m.weight, 1)\n",
        "      nn.init.constant_(m.bias,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRB2v5Fdx9mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kernel_size = 3\n",
        "#criterion = SSIM(kernel_size, reduction = 'mean)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzp6AcVdyBwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model    = BGDPTH()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "model.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model.to(model.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fgGPrATyZhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3,192,192))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEgzOZ2xybla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(),lr=0.001, momentum = 0.9, weight_decay = 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0thKIHDYy6RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  for batch_idx, data in enumerate(pbar):\n",
        "    data['f1'] = data['f1'].to(device)\n",
        "    data['f2'] = data['f2'].to(device)\n",
        "    data['f3'] = data['f3'].to(device)\n",
        "    data['f4'] = data['f4'].to(device)    \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "\n",
        " # breakpoint()\n",
        "\n",
        "    loss1 = criterion(output[0], data['f3'])\n",
        "    loss2 = criterion(output[1], data['f4'])\n",
        "    loss  = 2*loss1 + loss2\n",
        "\n",
        "    pbar.set_description(desc = f'loss={loss.item()} l1={loss1.item()} l2={loss2.item()}')   \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % prnt == 0:\n",
        "      #show_pred(output.detach().cpu(), nrow =2) # nrow = sqrt-bs\n",
        "      draw_and_save(output[0].detach().cpu(), f'plots/{epoch}_{batch-idx}_BR_{loss1.item()}.jpg')\n",
        "      draw_and_save(output[1].detach().cpu(), f'plots/{epoch}_{batch-idx}_DR_{loss2.item()}.jpg')\n",
        "      draw_and_save(data['f3'].detach().cpu(), f'plots/{epoch}_{batch-idx}_BG_{loss.item()}.jpg')\n",
        "      draw_and_save(data['f4'].detach().cpu(), f'plots/{epoch}_{batch-idx}_DG_{loss.item()}.jpg')\n",
        "      draw_and_save(data['f2'].detach().cpu(), f'plots/{epoch}_{batch-idx}_IN_{loss.item()}.jpg')\n",
        "\n",
        "      #show(data['f2'].detach().cpu(), nrow=5)\n",
        "\n",
        "    if batch_idx % 650 == 0:\n",
        "      torch.save(model.state_dict(),PATH/f'{epoch}_{batch_idx}_{loss.item()}.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axb3qffm1eRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "scheduler = StepLR(optim, step_size=2, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrXMgQFP4AHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1,2):\n",
        "  train(model, criterion,device, train_dl, optim, epoch)\n",
        "  #test(model, device, test_loader)\n",
        "  scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}